<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 5.4.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/all.min.css">

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"example.com","root":"/","scheme":"Gemini","version":"7.8.0","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":false,"show_result":false,"style":null},"back2top":{"enable":true,"sidebar":false,"scrollpercent":false},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":false,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}}};
  </script>

  <meta name="description" content="do">
<meta property="og:type" content="website">
<meta property="og:title" content="yukai">
<meta property="og:url" content="http://example.com/index.html">
<meta property="og:site_name" content="yukai">
<meta property="og:description" content="do">
<meta property="og:locale" content="zh_CN">
<meta property="article:author" content="wyukai">
<meta name="twitter:card" content="summary">

<link rel="canonical" href="http://example.com/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : true,
    isPost : false,
    lang   : 'zh-CN'
  };
</script>

  <title>yukai</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">yukai</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-home fa-fw"></i>首页</a>

  </li>
        <li class="menu-item menu-item-about">

    <a href="/about/" rel="section"><i class="fa fa-user fa-fw"></i>关于</a>

  </li>
        <li class="menu-item menu-item-tags">

    <a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>标签</a>

  </li>
        <li class="menu-item menu-item-categories">

    <a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>分类</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>归档</a>

  </li>
  </ul>
</nav>




</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content index posts-expand">
            
      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://example.com/2022/01/19/OCR-CTPN%E7%AE%97%E6%B3%95%E9%9A%8F%E8%AE%B0/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="wyukai">
      <meta itemprop="description" content="do">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="yukai">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2022/01/19/OCR-CTPN%E7%AE%97%E6%B3%95%E9%9A%8F%E8%AE%B0/" class="post-title-link" itemprop="url">OCR-CTPN算法随记</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>
              

              <time title="创建时间：2022-01-19 14:24:07 / 修改时间：17:00:17" itemprop="dateCreated datePublished" datetime="2022-01-19T14:24:07+08:00">2022-01-19</time>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h3 id="CTPN文本检测算法"><a href="#CTPN文本检测算法" class="headerlink" title="CTPN文本检测算法"></a>CTPN文本检测算法</h3><p>不同于自然界的其他单独物体，例如行人，物品等，文本信息蕴含更多的序列信息，文本可以由”单个字符、字符的一部分、多个字符”组织成一个sequence，文本目标不像行人 或者物体这种普通目标具有独立，封闭的范围。所以在目标检测算法中融入循环神经网络（RNN, LSTM），利用上下文信息进行文本检测是一个不错的方法。</p>
<p>文本检测相较于一般的目标检测，主要有以下几种区别：</p>
<ul>
<li>文本信息边界不易确定， 例如单词内的空格与单词间的空格会导致文本的边界范围不清晰。</li>
<li>文本信息蕴含序列特征，上下文的序列信息有助于文本检测。</li>
<li>文本行的长度变化范围较大，相比如普通物体的尺度信息，普通检测算法难以生成质量好的Region Proposal(或者称为 Text Proposal)。</li>
</ul>
<p><img src="../images/OCR-CTPN%E7%AE%97%E6%B3%95%E9%9A%8F%E8%AE%B0/image-20220119144903230.png" alt="image-20220119144903230"></p>
<p>上图展示了用Faster-RCNN网络和CTPN的检测效果，可以看到通用的目标检测算法的检测框会偏移较多，且对文本信息的边界定义比较模糊，而CTPN算法要准确的多。</p>
<p>CTPN的整体架构如下图所示：</p>
<ul>
<li>采用VGG-16作为检测网络的BackBone，下采样16倍后在Conv5之后提取空间特征信息，输出维度为B × W × H × C；</li>
<li>在Conv5的特征图上进行3x3xC的卷积，输出维度仍为B × W × H × C，这一步中的每一个特征点都融合了周围3 × 3的信息。（原始论文中采用的caffe的img2col进行特征的Reshape，这里采用3x3xC卷积代替，pytorch/tensorflow框架下的实现）。</li>
<li>接着将B × W × H × C维度的特征Reshape为(BH) × W × C的特征，然后作为双向LSTM的输入提取每一行的的序列特征，最后输出特征维度为(BH) × W × 256，然后Reshape至B x 256 x H x W。</li>
<li>经过FC，输出B x H x W x 512。</li>
<li>N × H × W × 512 最后会经过一个类似RPN的网络，分成三个预测支路：如上图所示，其中一个分支输出N × H × W × 2k，这里的k指的是每个像素对应k个anchor，这里的2K指的是对某一个anchor的预测<script type="math/tex">v = [{v_c},{v_h}]</script>；第二个分支输出N × H × W × 2k，这里的2K指的是2K个前景背景得分，记做。最后一个分支输出N × H × W × k，这里是K个side-refinement，预测某个anchor预测<img src="../images/OCR-CTPN%E7%AE%97%E6%B3%95%E9%9A%8F%E8%AE%B0/equation.svg+xml" alt="[公式]"></li>
<li>RPN之后会输出类似下图b中的text proposal, 然后适用NMS进行过滤。</li>
<li>后处理，使用文本线构造方法合成一个完成的文本行，同时矫正倾斜的情况。</li>
</ul>
<p><img src="../images/OCR-CTPN%E7%AE%97%E6%B3%95%E9%9A%8F%E8%AE%B0/image-20220119144559264.png" alt="image-20220119144559264"></p>
<h3 id="双向LSTM"><a href="#双向LSTM" class="headerlink" title="双向LSTM"></a>双向LSTM</h3><p>VGG16提取的是空间特征，而LSTM学习的就是序列特征，而这里使用的是双向LSTM，更好的避免RNN当中的遗忘问题，更完整地提取出序列特征。</p>
<p><img src="../images/OCR-CTPN%E7%AE%97%E6%B3%95%E9%9A%8F%E8%AE%B0/image-20220119155253540.png" alt="image-20220119155253540"></p>
<h3 id="Text-Proposal生成"><a href="#Text-Proposal生成" class="headerlink" title="Text Proposal生成"></a>Text Proposal生成</h3><p>文本长度的剧烈变化是文本检测的挑战之一，作者认为文本在长度的变化比高度的变化剧烈得多，文本边界开始与结束的地方难以和Faster-rcnn一样去用anchor匹配回归，所以作者提出一种<strong>vertical anchor</strong>的方法，即<strong>我们只去预测文本的竖直方向上的位置，不去预测水平方向的位置，水平位置的确定只需要我们检测一个一个小的固定宽度的文本段，将他们对应的高度预测准确，最后再将他们连接在一起，就得到了我们的文本行</strong>，如下图所示：</p>
<p><img src="../images/OCR-CTPN%E7%AE%97%E6%B3%95%E9%9A%8F%E8%AE%B0/image-20220119151722196.png" alt="image-20220119151722196"></p>
<p>对于每个像素点设置的anchor的宽度都是固定的，为16像素（原图），对应到特征图上就为1个像素（下采用了16倍）。而高度则是从11到273变化，这里我们每个像素点取k=10个anchor。</p>
<p><img src="../images/OCR-CTPN%E7%AE%97%E6%B3%95%E9%9A%8F%E8%AE%B0/image-20220119163202430.png" alt="image-20220119163202430"></p>
<p><img src="../images/OCR-CTPN%E7%AE%97%E6%B3%95%E9%9A%8F%E8%AE%B0/image-20220119152255022.png" alt="image-20220119152255022" style="zoom:67%;" /></p>
<p>这样设置Anchors是为了：</p>
<ol>
<li>保证在 x方向上，Anchor覆盖原图每个点且不相互重叠。</li>
<li>不同文本在 y 方向上高度差距很大，所以设置Anchors高度为11-283，用于覆盖不同高度的文本目标。</li>
</ol>
<p>获得Anchor后，与Faster R-CNN类似，CTPN会做如下处理：</p>
<ol>
<li>Softmax判断Anchor中是否包含文本，即选出Softmax score大的正Anchor</li>
<li>Bounding box regression修正包含文本的Anchor的<strong>中心y坐标</strong>与<strong>高度</strong>。</li>
</ol>
<p>因为宽度是固定的，所以只需要anchor的中心的y坐标以及anchor的高度就可以确定一个anchor，其中带星号的为ground-truth，没有带星号的则是预测值，带a的则是对应anchor的值。</p>
<p><img src="../images/OCR-CTPN%E7%AE%97%E6%B3%95%E9%9A%8F%E8%AE%B0/image-20220119152533923.png" alt="image-20220119152533923"></p>
<h3 id="RPN层"><a href="#RPN层" class="headerlink" title="RPN层"></a>RPN层</h3><p>CTPN的RPN层和Faster R-CNN很像，</p>
<p>第一个分支输出的是anchor的位置，也就是anchor的两个参数，因为每个特征点配置10个anchor，所以这个分支的输出20个channel。</p>
<p>第二个分支则是输出前景背景的得分情况(text/non-text scores)，通过softmax计算得分，所以这里也是输出20个channel。</p>
<p>第三个分支则是输出最后水平精修side-refinement的比例o，这是由于每个anchor的宽是一定的，所以有时候会导致水平方向有一点不准，所以这时候就需要校准一下检测框。</p>
<p><img src="../images/OCR-CTPN%E7%AE%97%E6%B3%95%E9%9A%8F%E8%AE%B0/image-20220119155746789.png" alt="image-20220119155746789"></p>
<p>Xside标识检测框的左边界或者右边界，Cx 表示anchor中心的横坐标。Wa是anchor固定的宽度16个像素。可以把这个o理解为一个缩放的比例，来对最后的结果做一个准确的拉伸，下面这张图中红色的就是使用了side-refinement，黄色的则是没有使用的结果。</p>
<p><img src="../images/OCR-CTPN%E7%AE%97%E6%B3%95%E9%9A%8F%E8%AE%B0/image-20220119160052651.png" alt="image-20220119160052651" style="zoom:67%;" /></p>
<h3 id="文本线构造方法"><a href="#文本线构造方法" class="headerlink" title="文本线构造方法"></a>文本线构造方法</h3><p>经过RPN之后生成一串或者多串text proposal , 然后用文本线构造办法，把这些text proposal连接成一个文本检测框。</p>
<p><img src="../images/OCR-CTPN%E7%AE%97%E6%B3%95%E9%9A%8F%E8%AE%B0/image-20220119163644749.png" alt="image-20220119163644749" style="zoom: 67%;" /></p>
<p>为了说明问题，假设某张图有上图所示的2个text proposal，即蓝色和红色2组Anchor，CTPN采用如下算法构造文本线：</p>
<ol>
<li>按照水平 x 坐标排序Anchor</li>
<li>按照规则依次计算每个Anchor <script type="math/tex">bo{x_j}</script>的 <script type="math/tex">pair(bo{x_j})</script>，组成 <script type="math/tex">pair(bo{x_i},bo{x_j})</script></li>
<li>通过<script type="math/tex">pair(bo{x_i},bo{x_j})</script>建立一个Connect graph，最终获得文本检测框。</li>
</ol>
<p><strong>文本线构造算法通过如下方式建立每个Anchor</strong>  <script type="math/tex">bo{x_j}</script>的   <script type="math/tex">pair(bo{x_i},bo{x_j})</script><strong>：</strong></p>
<ul>
<li>正向寻找：<ul>
<li><ol>
<li>沿水平正方向，寻找和box_i水平距离小于50像素的候选Anchors（每个Anchor宽16像素，也就是最多正向找50/16=3个）</li>
<li>从候选Anchor中，挑出与box_i竖直方向<script type="math/tex">overla{p_v} > 0.7</script> 的Anchor</li>
<li>挑出符合条件2中Softmax Score最大的box_j</li>
</ol>
</li>
</ul>
</li>
<li>反向寻找<ul>
<li><ol>
<li>沿水平负方向，寻找和box_i水平距离小于50像素的候选Anchors</li>
<li>从候选Anchor中，挑出与box_j竖直方向<script type="math/tex">overla{p_v} > 0.7</script> 的Anchor</li>
<li>挑出符合条件2中Softmax Score最大的box_k</li>
</ol>
</li>
</ul>
</li>
<li>对比score_i 和 score_j:<ul>
<li><ol>
<li>如果<script type="math/tex">scor{e_i} >  = scor{e_k}</script> ,则说明这是一个长连接，则设置Graph(i,j) = True;</li>
<li>如果<script type="math/tex">scor{e_i} < scor{e_k}</script>, 则说明这不是一个最长的连接（即该连接肯定包含在另外一个更长的连接中）。</li>
</ol>
</li>
</ul>
</li>
</ul>
<p><img src="../images/OCR-CTPN%E7%AE%97%E6%B3%95%E9%9A%8F%E8%AE%B0/image-20220119165416880.png" alt="image-20220119165416880"></p>
<h3 id="Loss"><a href="#Loss" class="headerlink" title="Loss"></a>Loss</h3><p>CTPN的损失函数如下图，分为三个部分：</p>
<p>(1) LS：每个anchor是否是正样本的classification loss</p>
<p>(2) Lv:每个anchor的中心y坐标和高度loss</p>
<p>(3) L0:文本区域两侧精修的x损失</p>
<p>和Faster-RCNN一样，以上的loss都采用smooth L1 loss。</p>
<p><img src="../images/OCR-CTPN%E7%AE%97%E6%B3%95%E9%9A%8F%E8%AE%B0/image-20220119165742503.png" alt="image-20220119165742503"></p>
<h3 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h3><ul>
<li><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/137540923">https://zhuanlan.zhihu.com/p/137540923</a></li>
<li><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/34757009">https://zhuanlan.zhihu.com/p/34757009</a></li>
<li><a target="_blank" rel="noopener" href="https://analyticsindiamag.com/complete-guide-to-bidirectional-lstm-with-python-codes/">https://analyticsindiamag.com/complete-guide-to-bidirectional-lstm-with-python-codes/</a></li>
</ul>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://example.com/2022/01/12/OCR%E6%95%B0%E6%8D%AE%E5%90%88%E6%88%90%E4%B9%8Btext-renderer/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="wyukai">
      <meta itemprop="description" content="do">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="yukai">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2022/01/12/OCR%E6%95%B0%E6%8D%AE%E5%90%88%E6%88%90%E4%B9%8Btext-renderer/" class="post-title-link" itemprop="url">OCR数据合成之text_renderer</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2022-01-12 16:41:38" itemprop="dateCreated datePublished" datetime="2022-01-12T16:41:38+08:00">2022-01-12</time>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          
      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://example.com/2022/01/11/OCR-%E5%B7%A5%E4%B8%9A%E5%AD%97%E7%AC%A6%E6%A3%80%E6%B5%8B%E5%AE%9E%E8%B7%B5/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="wyukai">
      <meta itemprop="description" content="do">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="yukai">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2022/01/11/OCR-%E5%B7%A5%E4%B8%9A%E5%AD%97%E7%AC%A6%E6%A3%80%E6%B5%8B%E5%AE%9E%E8%B7%B5/" class="post-title-link" itemprop="url">OCR-工业字符检测实践</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2022-01-11 11:24:21" itemprop="dateCreated datePublished" datetime="2022-01-11T11:24:21+08:00">2022-01-11</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2022-01-19 14:24:40" itemprop="dateModified" datetime="2022-01-19T14:24:40+08:00">2022-01-19</time>
              </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h3 id="1-PaddleOCR"><a href="#1-PaddleOCR" class="headerlink" title="1. PaddleOCR"></a>1. PaddleOCR</h3><ul>
<li>使用PPOCRLabel标注，完成自定义训练数据集的准备；</li>
<li>训练文本检测模型；</li>
<li>训练文本识别模型；</li>
<li>训练模型转换为inference模型；</li>
<li>基于python引擎的PP-OCR模型推理预测，串联检测+识别。</li>
</ul>
<h3 id="2-PPOCRLabel"><a href="#2-PPOCRLabel" class="headerlink" title="2. PPOCRLabel"></a>2. PPOCRLabel</h3><p>PPOCRLabel是一款适用于OCR领域的半自动化图形标注工具，内置PP-OCR模型对数据自动标注和重新识别。使用Python3和PyQT5编写，支持矩形框标注和四点标注模式，导出格式可直接用于PaddleOCR检测和识别模型的训练。</p>
<ul>
<li><a target="_blank" rel="noopener" href="https://github.com/PaddlePaddle/PaddleOCR/blob/release/2.4/PPOCRLabel/README_ch.md">https://github.com/PaddlePaddle/PaddleOCR/blob/release/2.4/PPOCRLabel/README_ch.md</a></li>
</ul>
<p><img src="../images/OCR-%E5%B7%A5%E4%B8%9A%E5%AD%97%E7%AC%A6%E6%A3%80%E6%B5%8B%E5%AE%9E%E8%B7%B5/steps.gif" alt="img"></p>
<p>使用步骤：</p>
<ul>
<li>cd ./PPOCRLabel  </li>
<li>python .\PPOCRLabel.py —lang ch</li>
<li>打开待标注文件夹，加载标注图像</li>
<li>勾选 文件/自动导出标记结果</li>
<li>标注</li>
<li>导出识别结果（切小图）</li>
</ul>
<h3 id="3-训练文本检测模型"><a href="#3-训练文本检测模型" class="headerlink" title="3. 训练文本检测模型"></a>3. 训练文本检测模型</h3>
      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://example.com/2022/01/07/Bounding-Box-Regression-Loss/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="wyukai">
      <meta itemprop="description" content="do">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="yukai">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2022/01/07/Bounding-Box-Regression-Loss/" class="post-title-link" itemprop="url">Bounding Box Regression Loss</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>
              

              <time title="创建时间：2022-01-07 14:36:31 / 修改时间：14:49:12" itemprop="dateCreated datePublished" datetime="2022-01-07T14:36:31+08:00">2022-01-07</time>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h3 id="1"><a href="#1" class="headerlink" title="### 1."></a>### 1.</h3><p>边界框回归的三大几何因素：重叠面积、中心点距离、纵横比</p>
<ul>
<li>IOU Loss：考虑了重叠面积，归一化坐标尺度</li>
<li>GIOU Loss：考虑了重叠面积，基于IOU解决边界框不相交时loss等于0的问题</li>
<li>DIOU Loss：考虑了重叠面积和中心点距离，基于IOU解决GIOU收敛慢的问题</li>
<li>CIOU Loss：考虑了重叠面积、中心点距离、纵横比，基于DIOU提升回归精确度</li>
<li>EIOU Loss：考虑了重叠面积，中心点距离、长宽边长真实差，基于CIOU解决了纵横比的模糊定义，并添加Focal Loss解决BBox回归中的样本不平衡问题</li>
</ul>
<p><img src="../images/Bounding-Box-Regression-Loss/image-20220107144907598.png" alt="image-20220107144907598" style="zoom:80%;" /></p>
<h3 id="5-Reference"><a href="#5-Reference" class="headerlink" title="5. Reference"></a>5. Reference</h3><ul>
<li><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/270663039">https://zhuanlan.zhihu.com/p/270663039</a></li>
<li><a target="_blank" rel="noopener" href="https://blog.csdn.net/amusi1994/article/details/112966895">https://blog.csdn.net/amusi1994/article/details/112966895</a></li>
<li><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/375745293">https://zhuanlan.zhihu.com/p/375745293</a></li>
</ul>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://example.com/2022/01/06/RoI-Pooling-%E4%B8%8E-RoI-Align/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="wyukai">
      <meta itemprop="description" content="do">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="yukai">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2022/01/06/RoI-Pooling-%E4%B8%8E-RoI-Align/" class="post-title-link" itemprop="url">RoI Pooling, RoI Align, PS-RoI Pooling</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>
              

              <time title="创建时间：2022-01-06 10:21:38 / 修改时间：14:31:20" itemprop="dateCreated datePublished" datetime="2022-01-06T10:21:38+08:00">2022-01-06</time>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h3 id="1-RoI"><a href="#1-RoI" class="headerlink" title="1. RoI"></a>1. RoI</h3><p>RoI(Region of Interest), 从原图中通过某些区域选择方法得到的候选区域。</p>
<p>量化（quantization）是指将输入连续值（或者大量可能的离散值）采样为有限多个离散值的过程。或者理解为，将输入数据集（如实数）约束到离散集（如整数）的过程。</p>
<p>RoI Pooling 和 RoI Align 均是将任意大小的特征图（输入），映射为固定尺寸的特征（输出）。</p>
<h3 id="2-RoI-Pooling"><a href="#2-RoI-Pooling" class="headerlink" title="2. RoI Pooling"></a>2. RoI Pooling</h3><p><img src="../images/RoI-Pooling-%E4%B8%8E-RoI-Align/image-20220106102835274.png" alt="image-20220106102835274" style="zoom:50%;" /></p>
<p>RoI Pooling的作用本质上是为了将不同尺寸的RoI特征转换为相同的特征图输出，保证特征图展开（flatten）后具有相同的大小尺寸，能够与下层的全连接层连接，分别执行线性分类(linear classifier)和边框回归(bounding box regressor)</p>
<ul>
<li><p>1 将RoI 对齐到特征图的网格单元（snap to grid cell）</p>
<p>首先将特征图上的浮点数RoI（举例 ： 665 <em> 665 —&gt; 665/32=20.78 —&gt;  20.78 </em> 20.78 —&gt; 20 <em> 20）进行量化。下图中绿色框为RoI对应的实际区域（<em>*由于经过特征尺度变换，导致RoI的坐标会可能会落到特征图的单元之间</em></em>）， 蓝色框代表量化(网格对齐)后的RoI所对应的特征图。</p>
</li>
</ul>
<p><img src="../images/RoI-Pooling-%E4%B8%8E-RoI-Align/image-20220106103613312.png" alt="image-20220106103613312" style="zoom:50%;" /></p>
<p><img src="../images/RoI-Pooling-%E4%B8%8E-RoI-Align/image-20220106105319288.png" alt="image-20220106105319288" style="zoom:67%;" /></p>
<ul>
<li><p>2 划分网格为子区域</p>
<p>将上一步得到的量化RoI 特征进一步细分为量化的空间单元(bin)。为了得到输出的特征图为 2 <em> 2 </em> 512 ，这里的量化操作就是将上一步的到量化特征图划分为2 <em> 2个特征单元。如果无法通过直接均分得到量化的子区域，通过分别采取向上取整（ceil）和向下取整（floor）的到对应的单元尺寸大小。以当前 4 </em> 5 尺寸的特征图为例，对于宽度方向 4 / 2 = 2， 对于高度方向 5 /  2 = 2.5)， 通过向上和向下取整整，确定高度方向特征子区域的大小分别为2和3。</p>
</li>
</ul>
<p><img src="../images/RoI-Pooling-%E4%B8%8E-RoI-Align/image-20220106110344846.png" alt="image-20220106110344846" style="zoom: 67%;" /></p>
<ul>
<li>3 子区域最大池化</li>
</ul>
<p>在每一个子区域执行聚合操作得到单元的特征值（一般是最大池化）。对上一步得到的 2 <em> 2个子区域分别做最大池化操作，得到 2 </em> 2 * 512的目标特征图。</p>
<p>缺陷</p>
<p>每一次量化操作都会对应着轻微的区域特征错位（misaligned）， 这些量化操作在RoI和提取到的特征之间引入了偏差。这些量化可能不会影响对分类任务，但它对预测像素精度掩模有很大的负面影响。</p>
<h3 id="3-RoI-Align"><a href="#3-RoI-Align" class="headerlink" title="3. RoI Align"></a>3. RoI Align</h3><p>RoI Align在Mask RCNN中被首次提出，是针对RoI Pooling 在语义分割等精细度任务中的精确度的问题提出的改进方案。</p>
<ul>
<li>1 遍历候选每个候选区域，保持浮点数边界不做量化（不对齐网格单元）；同时平均分网格分为 2 * 2个子网格区域，每个单元的边界也不做量化。</li>
</ul>
<p><img src="../images/RoI-Pooling-%E4%B8%8E-RoI-Align/image-20220106110933568.png" alt="image-20220106110933568" style="zoom:67%;" /></p>
<ul>
<li><p>2 对于每个区域选择4个规则采样点（分别对应将区域进一步平均分为四个区域，取每个子区域的中点)。</p>
<p><img src="../images/RoI-Pooling-%E4%B8%8E-RoI-Align/image-20220106111115211.png" alt="image-20220106111115211" style="zoom:67%;" /></p>
</li>
<li><p>3 利用双线性插值计算得到四个采用点的像素值大小。下图为一个规则采样点所对应的邻近区域示意图。</p>
</li>
</ul>
<p><img src="../images/RoI-Pooling-%E4%B8%8E-RoI-Align/image-20220106111143717.png" alt="image-20220106111143717" style="zoom:67%;" /></p>
<ul>
<li>4 利用最大池化（max pooling）或平均池化(average pooling)分别对每个子区域执行聚合操作，得到最终的特征图。</li>
</ul>
<p><img src="../images/RoI-Pooling-%E4%B8%8E-RoI-Align/image-20220106111213485.png" alt="image-20220106111213485" style="zoom:67%;" /></p>
<p>下图 绿色表示ROI区域额外信息， 蓝色(第一次量化)和天蓝色(第二次量化)表示丢失信息</p>
<p><img src="../images/RoI-Pooling-%E4%B8%8E-RoI-Align/image-20220106112934397.png" alt="image-20220106112934397" style="zoom:80%;" /></p>
<h3 id="4-PS-RoI-Pooling"><a href="#4-PS-RoI-Pooling" class="headerlink" title="4. PS-RoI Pooling"></a>4. PS-RoI Pooling</h3><p>位置敏感池化，RFCN引入位置敏感池化，主要基于以下两方面原因</p>
<ol>
<li>引入位置敏感，卷积可以保持位置信息，但是经过全连接后，位置信息不在保留。</li>
<li>对于region-based方法，通常会分为几个sub-network, 一是提取图像特征的主干网络，与region无关，各region共享，计算量大。二是生成候选区域的RPN网络，三是用来分类和回归的prediction网络， 每个region会单独执行这部分sub-network。而RFCN将计算量大卷积尽可能地移到共享的主干网络中，最后仅使用一层卷积做prediction，减少了计算量。</li>
</ol>
<p>为了实现位置敏感就提出PS-ROI Pooling，核心思想是position sensitive score map。<br>把位置信息以层的形式就组成position sensitive score maps，进行一次卷积就计算了多个ROI的最终输出(固定长度)。</p>
<p><img src="../images/RoI-Pooling-%E4%B8%8E-RoI-Align/image-20220106135532044.png" alt="image-20220106135532044" style="zoom:80%;" /></p>
<ul>
<li>首先，在共享特征图之后添加1 <em> 1 </em> k^2(c+1)维的卷积形成位置敏感特征图，然后在位置敏感特征图上进行PS-RoI Pooling。 k^2代表的是RoI中划分的位置区域数目。比如k=3, 即代表上左（左上角），上中，上右，中左，中中，中右，下左，下中，下右（右下角）共9个子区域。 c+1 代表所有类别加上背景。 k^2(c+1)张特征图每c+1张分成一组，共包含k^2组，每一组负责其对应区域的响应，如上图所示。</li>
<li>然后进行PS-RoI Pooling，对位置敏感特征图上的RoI区域划分子区域（k^2）, 每个对应位置（c+1）内进行全局平均池化， 最后获得一组（c+1）* k^2的投票矩阵。</li>
<li>最后，每个类对应有9个位置的投票值，这9个值求和，就是这个类的概率。</li>
</ul>
<h3 id="5-RoI-Align的反向传播"><a href="#5-RoI-Align的反向传播" class="headerlink" title="5. RoI Align的反向传播"></a>5. RoI Align的反向传播</h3><p>和ROI Pooling核心思想是一样的，但是在ROI Align中，i ∗ ( r , j )是一个浮点数的坐标位置(前向传播时计算出来的采样点)，在池化前的特征图中，每一个与 i ∗ ( r , j ) 横纵坐标均小于1的点都应该接受与此对应的点y(r，j)回传的梯度，故ROI Align 的反向传播公式如下:<br><img src="../images/RoI-Pooling-%E4%B8%8E-RoI-Align/image-20220106142854108.png" alt="image-20220106142854108"></p>
<p>上式中，d(.)表示两点之间的距离，Δ h 和Δ w 表示 i 与 i ∗ ( r , j )横纵坐标的差值，这里作为双线性内插的系数乘在原始的梯度上。</p>
<h3 id="6-Reference"><a href="#6-Reference" class="headerlink" title="6 . Reference"></a>6 . Reference</h3><ol>
<li><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/161540817">https://zhuanlan.zhihu.com/p/161540817</a></li>
<li><a target="_blank" rel="noopener" href="https://cloud.tencent.com/developer/article/1689064">https://cloud.tencent.com/developer/article/1689064</a></li>
</ol>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://example.com/2022/01/04/%E5%9B%BE%E5%83%8F%E7%9B%B8%E4%BC%BC%E5%BA%A6%E8%AE%A1%E7%AE%97%E6%96%B9%E5%BC%8F/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="wyukai">
      <meta itemprop="description" content="do">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="yukai">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2022/01/04/%E5%9B%BE%E5%83%8F%E7%9B%B8%E4%BC%BC%E5%BA%A6%E8%AE%A1%E7%AE%97%E6%96%B9%E5%BC%8F/" class="post-title-link" itemprop="url">图像相似度计算方式</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2022-01-04 10:32:37" itemprop="dateCreated datePublished" datetime="2022-01-04T10:32:37+08:00">2022-01-04</time>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          
      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://example.com/2021/12/28/%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B%E4%B8%AD%E7%9A%84FPN/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="wyukai">
      <meta itemprop="description" content="do">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="yukai">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2021/12/28/%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B%E4%B8%AD%E7%9A%84FPN/" class="post-title-link" itemprop="url">目标检测中的FPN</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>
              

              <time title="创建时间：2021-12-28 17:17:24 / 修改时间：18:07:42" itemprop="dateCreated datePublished" datetime="2021-12-28T17:17:24+08:00">2021-12-28</time>
            </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/deep-learning/" itemprop="url" rel="index"><span itemprop="name">deep learning</span></a>
                </span>
                  ，
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/deep-learning/object-detection/" itemprop="url" rel="index"><span itemprop="name">object detection</span></a>
                </span>
                  ，
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/deep-learning/object-detection/ssl/" itemprop="url" rel="index"><span itemprop="name">ssl</span></a>
                </span>
                  ，
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/deep-learning/object-detection/ssl/image-classification/" itemprop="url" rel="index"><span itemprop="name">image classification</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <p>z 摘录自小纸屑 <a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/148738276">https://zhuanlan.zhihu.com/p/148738276</a></p>
<h3 id="1-简介"><a href="#1-简介" class="headerlink" title="1. 简介"></a>1. 简介</h3><p>FPN结构，特征金字塔网络，主要用作不同尺度的特征融合，从而提高目标检测算法的精度。</p>
<p><img src="../images/%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B%E4%B8%AD%E7%9A%84FPN/image-20211228172104469.png" alt="image-20211228172104469"></p>
<p>常见的物体检测算法，其实可以分解为三个递进的阶段：</p>
<ol>
<li><p>Backbone特征提取阶段</p>
<p>Backbone生成的特征，一般按stage划分，分别记作C1、C2、C3、C4、C5、C6、C7等，其中的数字与stage的编号相同，代表的是分辨率减半的次数，如C2代表stage2输出的特征图，分辨率为输入图片的1/4，C5代表，stage5输出的特征图，分辨率为输入图片的1/32。</p>
</li>
<li><p>Neck特征融合阶段</p>
<p>FPN一般将上一步生成的不同分辨率特征作为输入，输出经过融合后的特征。输出的特征一般以P作为编号标记。如FPN的输入是，C2、C3、C4、C5、C6，经过融合后，输出为P2、P3、P4、P5、P6。这个过程可以用数学公式表达：</p>
<p><img src="../images/%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B%E4%B8%AD%E7%9A%84FPN/image-20211228172506926.png" alt="image-20211228172506926"></p>
</li>
<li><p>Head检测阶段</p>
<p>FPN输出融合后的特征后，就可以输入到检测头做具体的物体检测。</p>
</li>
</ol>
<h3 id="2-FPN及其变种结构"><a href="#2-FPN及其变种结构" class="headerlink" title="2. FPN及其变种结构"></a>2. FPN及其变种结构</h3><p>物体检测性能提升，一般主要通过数据增强、改进Backbone、改进FPN、改进检测头、改进loss、改进后处理等6个常用手段。其中FPN自从被提出来，先后迭代了不少版本。大致迭代路径如下图：</p>
<p><img src="../images/%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B%E4%B8%AD%E7%9A%84FPN/image-20211228172706353.png" alt="image-20211228172706353"></p>
<ol>
<li>无融合  </li>
</ol>
<p>无融合，又利用多尺度特征的典型代表SSD，它直接利用不同stage的特征图分别负责不同scale大小物体的检测。</p>
<p><img src="../images/%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B%E4%B8%AD%E7%9A%84FPN/image-20211228172812278.png" alt="image-20211228172812278"></p>
<ol>
<li><p>自上而下单向融合</p>
<p>自上而下单向融合的FPN，事实上仍然是当前物体检测模型的主流融合模式。如我们常见的<a href="https://link.zhihu.com/?target=https%3A//arxiv.org/abs/1506.01497">Faster RCNN</a>、<a href="https://link.zhihu.com/?target=https%3A//arxiv.org/abs/1703.06870">Mask RCNN</a>、<a href="https://link.zhihu.com/?target=https%3A//pjreddie.com/media/files/papers/YOLOv3.pdf">Yolov3</a>、<a href="https://link.zhihu.com/?target=https%3A//arxiv.org/abs/1708.02002">RetinaNet</a>、<a href="https://link.zhihu.com/?target=https%3A//arxiv.org/abs/1712.00726">Cascade RCNN</a>等，具体各个FPN的内部细节如下图。</p>
<p><img src="../images/%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B%E4%B8%AD%E7%9A%84FPN/image-20211228172915560.png" alt="image-20211228172915560"></p>
</li>
</ol>
<p><strong>a）Faster/Master/Cascade RCNN中的FPN</strong></p>
<p>Faster/Master/Cascade RCNN中的FPN，利用了C2-C6五个stage的特征，其中C6是从C5直接施加1x1/2的MaxPooling操作得到。FPN融合后得到P2-P6，其中P6直接等于C6，P5是先经过1x1Conv，再经过3x3Conv得到，P2-P4均是先经过1x1Conv，再融合上一层2xUpsample的特征，再经过3x3Conv得到。具体过程可以看上图。</p>
<p><strong>b）RetinaNet中的FPN</strong></p>
<p>RetinaNet中的FPN，利用了C3-C7五个stage的特征，其中C6是从C5直接施加3x3/2的Conv操作得到，C7是从C6直接施加3x3/2的Conv操作得到。FPN融合后得到P3-P7，其中P6、P7直接等于C6、C7，P5是先经过1x1Conv，再经过3x3Conv得到，P3-P4均是先经过1x1Conv，再融合上一层2xUpsample的特征，再经过3x3Conv得到。具体过程可以看上图。</p>
<p>可以看出，RetinaNet基本与Faster/Master/Cascade RCNN中的FPN一脉相承。只是利用的stage的特征略有差别，Faster/Master/Cascade RCNN利用了高分辨率低语义的C2，RetinaNet利用了更低分辨率更高语义的C7。其他都是细微的差别。</p>
<p><strong>c）Yolov3中的FPN</strong></p>
<p>Yolov3中的FPN与上述两个有比较大的区别。首先，Yolov3中的FPN只利用到了C3-C5三个stage的特征；其次，从C5征到P5特征，会先经过5层Conv，然后再经过一层3x3Conv；最后，C3-C4到P3-P4特征，上一层特征会先经过1x1Conv+2xUpsample，然后先与本层特征concatenate，再经过5层Conv，之后经过一层3x3Conv。</p>
<ol>
<li>简单双向融合</li>
</ol>
<p>FPN自从提出来以后，均是只有从上向下的融合，<a href="https://link.zhihu.com/?target=https%3A//arxiv.org/abs/1803.01534">PANet</a>是第一个提出从下向上二次融合的模型，并且PANet就是在Faster/Master/Cascade RCNN中的FPN的基础上，简单增了从下而上的融合路径。看下图。</p>
<p><img src="../images/%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B%E4%B8%AD%E7%9A%84FPN/image-20211228173101063.png" alt="image-20211228173101063"></p>
<ol>
<li>复杂的双向融合</li>
</ol>
<p>PANet的提出证明了双向融合的有效性，而PANet的双向融合较为简单，因此不少文章在FPN的方向上更进一步，尝试了更复杂的双向融合，如<a href="https://link.zhihu.com/?target=https%3A//arxiv.org/abs/1911.09516">ASFF</a>、<a href="https://link.zhihu.com/?target=https%3A//arxiv.org/abs/1904.07392">NAS-FPN</a>和<a href="https://link.zhihu.com/?target=https%3A//arxiv.org/abs/1911.09070">BiFPN</a>。</p>
<p><strong>ASFF</strong><br>ASFF（论文：Learning Spatial Fusion for Single-Shot Object Detection）作者在YOLOV3的FPN的基础上，研究了每一个stage再次融合三个stage特征的效果。如下图。其中不同stage特征的融合，采用了注意力机制，这样就可以控制其他stage对本stage特征的贡献度。</p>
<p><img src="../images/%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B%E4%B8%AD%E7%9A%84FPN/image-20211228173150634.png" alt="image-20211228173150634"></p>
<p><strong>NAS-FPN和BiFPN</strong><br>NAS-FPN和BiFPN，都是google出品，思路也一脉相承，都是在FPN中寻找一个有效的block，然后重复叠加，这样就可以弹性的控制FPN的大小。</p>
<p><img src="../images/%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B%E4%B8%AD%E7%9A%84FPN/image-20211228173207992.png" alt="image-20211228173207992"></p>
<p>其中BiFPN的具体细节如下图。</p>
<p>改进点1，删除入度为1的节点，如果一个节点只有一个输入边且没有特征融合，那么它将对旨在融合不同特征的特征网络贡献较小。</p>
<p>改进点2，添加跳跃连接。如果原始输入和输出节点处于同一level，则在原始输入和输出节点之间添加一条额外的边，以便在不增加成本的情况下融合更多特征。</p>
<p>改进点3，将BiFPN视作一个基本单元，重复堆叠。不像PANet那样只有一个top-down和bottom-up路径，BiFPN将一对路径视为一个特征层，然后重复多次以得到更多高层特征融合。</p>
<p><img src="../images/%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B%E4%B8%AD%E7%9A%84FPN/image-20211228173236688.png" alt="image-20211228173236688"></p>
<p><img src="../images/%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B%E4%B8%AD%E7%9A%84FPN/image-20211228173943134.png" alt="image-20211228173943134"></p>
<ol>
<li><p><strong>Recursive-FPN</strong></p>
<p>Paper: <a href="https://link.zhihu.com/?target=https%3A//arxiv.org/abs/2006.02334">DetectoRS: Detecting Objects with Recursive Feature Pyramid and Switchable Atrous Convolution</a></p>
<p>递归FPN理解起来很容易，就是将传统FPN的融合后的输出，再输入给Backbone，进行二次循环，如下图。</p>
</li>
</ol>
<p><img src="../images/%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B%E4%B8%AD%E7%9A%84FPN/image-20211228173603992.png" alt="image-20211228173603992"></p>
<p>下图给出了FPN与Recursive-FPN的区别，并且把一个2层的递归FPN展开了，非常简单明了，不做过多介绍。</p>
<p><img src="../images/%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B%E4%B8%AD%E7%9A%84FPN/image-20211228173616868.png" alt="image-20211228173616868"></p>
<h3 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h3><ol>
<li><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/148738276">https://zhuanlan.zhihu.com/p/148738276</a></li>
</ol>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://example.com/2021/12/28/ASFF/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="wyukai">
      <meta itemprop="description" content="do">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="yukai">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2021/12/28/ASFF/" class="post-title-link" itemprop="url">ASFF</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2021-12-28 10:36:52" itemprop="dateCreated datePublished" datetime="2021-12-28T10:36:52+08:00">2021-12-28</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2021-12-31 15:04:44" itemprop="dateModified" datetime="2021-12-31T15:04:44+08:00">2021-12-31</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/deep-learning/" itemprop="url" rel="index"><span itemprop="name">deep learning</span></a>
                </span>
                  ，
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/deep-learning/object-detection/" itemprop="url" rel="index"><span itemprop="name">object detection</span></a>
                </span>
                  ，
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/deep-learning/object-detection/ssl/" itemprop="url" rel="index"><span itemprop="name">ssl</span></a>
                </span>
                  ，
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/deep-learning/object-detection/ssl/image-classification/" itemprop="url" rel="index"><span itemprop="name">image classification</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h2 id="YOLOV3-ASFF"><a href="#YOLOV3-ASFF" class="headerlink" title="YOLOV3-ASFF"></a>YOLOV3-ASFF</h2><h3 id="1-简介"><a href="#1-简介" class="headerlink" title="1. 简介"></a>1. 简介</h3><p>  YOLOV3-ASFF为了解决FPN不同特征尺度之间的不一致问题，提出自适应空间特征融合策略。它通过设置可学习权重因子对不同尺度的特征进行自适应(可学习)融合，通过在空间上过滤冲突信息从而抑制梯度反传时的不一致问题，从而改善了特征的比例不变性，也降低了时间开销。</p>
<p><img src="../images/ASFF/image-20211228151839649.png" alt="image-20211228151839649"></p>
<p>除了自适应空间特征融合，YOLOv3-ASFF在YOLOv3基础上博采众长，集合了MixUp数据增强，学习率cosine衰减策略，异步BN，Guided Anchoring，回归loss改为IoU loss等一系列tricks。 其strong yolov3-608 在COCO2017上达到了 38.8AP + 50fps的效果， 超过了原始YOLOv3-608 ： 33.0AP + 53fps。</p>
<blockquote>
<p>论文 <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/1911.09516v2.pdf">https://arxiv.org/pdf/1911.09516v2.pdf</a></p>
<p>code: <a target="_blank" rel="noopener" href="https://github.com/GOATmessi7/ASFF">https://github.com/GOATmessi7/ASFF</a></p>
</blockquote>
<h3 id="2-自适应空间特征融合（ASFF）"><a href="#2-自适应空间特征融合（ASFF）" class="headerlink" title="2.自适应空间特征融合（ASFF）"></a>2.自适应空间特征融合（ASFF）</h3><p><img src="../images/ASFF/image-20211228152822280.png" alt="image-20211228152822280"></p>
<p>在上图中， 绿色框里代表一个ASFF模块，X1, X2, X3代表level1, level2, level3三层的特征图，<script type="math/tex">\alpha, \beta, \gamma</script> 则为可学习的权重参数。 加权融合后特征最为Head层的输入。</p>
<p><img src="../images/ASFF/image-20211228153257070.png" alt="image-20211228153257070"></p>
<p>以ASFF-2举例说明：</p>
<ol>
<li>对Level1的特整图（1，512，10，10）压缩通道数， 然后插值后变为（1，256，20，20）的特征向量。</li>
<li>对Level3的特征图进行<script type="math/tex">k=3*3，s=2</script>卷积，输出特征图（1，256，20，20）</li>
<li>Level2层级上特征图不需改变，然后对三个层级的特征图进行<script type="math/tex">k=1*1，s=1</script>的卷积，得到三个层级的空间权重向量（1，16*3， 20，20）</li>
<li>对空间特征降维，并沿通道方向进行softmax操作，得到（1，3，20，20）的权重向量。</li>
<li>特征融合。</li>
</ol>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">ASFF</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, level, rfb=<span class="literal">False</span>, vis=<span class="literal">False</span></span>):</span></span><br><span class="line">        <span class="built_in">super</span>(ASFF, self).__init__()</span><br><span class="line">        self.level = level</span><br><span class="line">        self.dim = [<span class="number">512</span>, <span class="number">256</span>, <span class="number">256</span>]</span><br><span class="line">        self.inter_dim = self.dim[self.level]</span><br><span class="line">        <span class="keyword">if</span> level==<span class="number">0</span>:</span><br><span class="line">            self.stride_level_1 = add_conv(<span class="number">256</span>, self.inter_dim, <span class="number">3</span>, <span class="number">2</span>)</span><br><span class="line">            self.stride_level_2 = add_conv(<span class="number">256</span>, self.inter_dim, <span class="number">3</span>, <span class="number">2</span>)</span><br><span class="line">            self.expand = add_conv(self.inter_dim, <span class="number">1024</span>, <span class="number">3</span>, <span class="number">1</span>)</span><br><span class="line">        <span class="keyword">elif</span> level==<span class="number">1</span>:</span><br><span class="line">            self.compress_level_0 = add_conv(<span class="number">512</span>, self.inter_dim, <span class="number">1</span>, <span class="number">1</span>)</span><br><span class="line">            self.stride_level_2 = add_conv(<span class="number">256</span>, self.inter_dim, <span class="number">3</span>, <span class="number">2</span>)</span><br><span class="line">            self.expand = add_conv(self.inter_dim, <span class="number">512</span>, <span class="number">3</span>, <span class="number">1</span>)</span><br><span class="line">        <span class="keyword">elif</span> level==<span class="number">2</span>:</span><br><span class="line">            self.compress_level_0 = add_conv(<span class="number">512</span>, self.inter_dim, <span class="number">1</span>, <span class="number">1</span>)</span><br><span class="line">            self.expand = add_conv(self.inter_dim, <span class="number">256</span>, <span class="number">3</span>, <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">        compress_c = <span class="number">8</span> <span class="keyword">if</span> rfb <span class="keyword">else</span> <span class="number">16</span>  <span class="comment">#when adding rfb, we use half number of channels to save memory</span></span><br><span class="line"></span><br><span class="line">        self.weight_level_0 = add_conv(self.inter_dim, compress_c, <span class="number">1</span>, <span class="number">1</span>)</span><br><span class="line">        self.weight_level_1 = add_conv(self.inter_dim, compress_c, <span class="number">1</span>, <span class="number">1</span>)</span><br><span class="line">        self.weight_level_2 = add_conv(self.inter_dim, compress_c, <span class="number">1</span>, <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">        self.weight_levels = nn.Conv2d(compress_c*<span class="number">3</span>, <span class="number">3</span>, kernel_size=<span class="number">1</span>, stride=<span class="number">1</span>, padding=<span class="number">0</span>)</span><br><span class="line">        self.vis= vis</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, x_level_0, x_level_1, x_level_2</span>):</span></span><br><span class="line">        <span class="keyword">if</span> self.level==<span class="number">0</span>:</span><br><span class="line">            level_0_resized = x_level_0</span><br><span class="line">            level_1_resized = self.stride_level_1(x_level_1)</span><br><span class="line"></span><br><span class="line">            level_2_downsampled_inter =F.max_pool2d(x_level_2, <span class="number">3</span>, stride=<span class="number">2</span>, padding=<span class="number">1</span>)</span><br><span class="line">            level_2_resized = self.stride_level_2(level_2_downsampled_inter)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">elif</span> self.level==<span class="number">1</span>:</span><br><span class="line">            level_0_compressed = self.compress_level_0(x_level_0)    <span class="comment"># [1,512,10,10] --&gt;  [1,256,10,10] </span></span><br><span class="line">            level_0_resized =F.interpolate(level_0_compressed, scale_factor=<span class="number">2</span>, mode=<span class="string">&#x27;nearest&#x27;</span>) <span class="comment"># [1,256,20,20]</span></span><br><span class="line">            level_1_resized =x_level_1 <span class="comment"># [1,256,20,20]</span></span><br><span class="line">            level_2_resized =self.stride_level_2(x_level_2) <span class="comment">#[1,256,40,40] --&gt; [1,256, 20,20]</span></span><br><span class="line">        <span class="keyword">elif</span> self.level==<span class="number">2</span>:</span><br><span class="line">            level_0_compressed = self.compress_level_0(x_level_0)</span><br><span class="line">            level_0_resized =F.interpolate(level_0_compressed, scale_factor=<span class="number">4</span>, mode=<span class="string">&#x27;nearest&#x27;</span>)</span><br><span class="line">            level_1_resized =F.interpolate(x_level_1, scale_factor=<span class="number">2</span>, mode=<span class="string">&#x27;nearest&#x27;</span>)</span><br><span class="line">            level_2_resized =x_level_2</span><br><span class="line"></span><br><span class="line">        level_0_weight_v = self.weight_level_0(level_0_resized)  <span class="comment">#[1,16,20,20]</span></span><br><span class="line">        level_1_weight_v = self.weight_level_1(level_1_resized)  <span class="comment">#[1,16,20,20]</span></span><br><span class="line">        level_2_weight_v = self.weight_level_2(level_2_resized)  <span class="comment">#[1,16,20,20]</span></span><br><span class="line">        levels_weight_v = torch.cat((level_0_weight_v, level_1_weight_v, level_2_weight_v),<span class="number">1</span>)  <span class="comment">#[1,48,20,20]</span></span><br><span class="line">        levels_weight = self.weight_levels(levels_weight_v)  <span class="comment"># [1,3,20,20]</span></span><br><span class="line">        </span><br><span class="line">        levels_weight = F.softmax(levels_weight, dim=<span class="number">1</span>)  </span><br><span class="line">        </span><br><span class="line">        <span class="comment">#softmax激活函数对三个通道的各位置进行运算，对不同通道的特征赋予不同的权重（归一化后）,以达到自适应（可学习）的特征融合</span></span><br><span class="line">        fused_out_reduced = level_0_resized * levels_weight[:,<span class="number">0</span>:<span class="number">1</span>,:,:]+\</span><br><span class="line">                            level_1_resized * levels_weight[:,<span class="number">1</span>:<span class="number">2</span>,:,:]+\</span><br><span class="line">                            level_2_resized * levels_weight[:,<span class="number">2</span>:,:,:]</span><br><span class="line"></span><br><span class="line">        out = self.expand(fused_out_reduced)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> self.vis:</span><br><span class="line">            <span class="keyword">return</span> out, levels_weight, fused_out_reduced.<span class="built_in">sum</span>(dim=<span class="number">1</span>)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="keyword">return</span> out</span><br><span class="line"></span><br><span class="line"><span class="comment"># test</span></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    model = ASFF(level=<span class="number">1</span>)</span><br><span class="line">    l1 = torch.ones(<span class="number">1</span>,<span class="number">512</span>,<span class="number">10</span>,<span class="number">10</span>) <span class="comment">#  FPN --&gt; L1</span></span><br><span class="line">    l2 = torch.ones(<span class="number">1</span>,<span class="number">256</span>,<span class="number">20</span>,<span class="number">20</span>) <span class="comment">#  FPN --&gt; L2</span></span><br><span class="line">    l3 = torch.ones(<span class="number">1</span>,<span class="number">256</span>,<span class="number">40</span>,<span class="number">40</span>) <span class="comment">#  FPN --&gt; L3</span></span><br><span class="line"></span><br><span class="line">    out = model(l1,l2,l3)</span><br><span class="line">    <span class="built_in">print</span>(out.shape) <span class="comment">#[1,256,20,20]</span></span><br></pre></td></tr></table></figure>
<h3 id="3-ASFF的可解释性"><a href="#3-ASFF的可解释性" class="headerlink" title="3. ASFF的可解释性"></a>3. ASFF的可解释性</h3><p>以YOLOv3为例，加入FPN后通过链式法则在backward的时候梯度是这样计算的：</p>
<p><img src="../images/ASFF/image-20211228154404525.png" alt="image-20211228154404525"></p>
<p>通常情况下，特征图尺寸增大通过插值（interpolation）实现，特征图尺寸缩小通过pooling来实现，假设：</p>
<p><img src="../images/ASFF/image-20211228154629987.png" alt="image-20211228154629987"></p>
<p>对于融合运算(add, concat)，相当于对输出特征的activation操作，其导数也将为固定值，可以将它的值同样简化为1。</p>
<p><img src="../images/ASFF/image-20211228154848675.png" alt="image-20211228154848675"><img src="../images/ASFF/image-20211228154856380.png" alt="image-20211228154856380"></p>
<p>最终简化为：</p>
<p><img src="../images/ASFF/image-20211228155128091.png" alt="image-20211228155128091"></p>
<p>若Level1上的某位置上为正样本特征，那如果Level2, Level3上对应位置却为负样本，那么在反向传播的梯度中既包含正样本信息也包含负样本信息，就会造成信息的不一致性，从而降低Level1上各个特征的学习效率。而通过ASFF的方式，反向传播的梯度表达式就变成了：</p>
<p><img src="../images/ASFF/image-20211228155556739.png" alt="image-20211228155556739"></p>
<p>因此可以动态地学习权重参数，进行更优的特征融合。</p>
<p><img src="../images/ASFF/image-20211228155840045.png" alt="image-20211228155840045"></p>
<p>上图可视化的结果进一步阐明了ASFF的有效性。比如大尺度的目标，可以看到斑马实际上是在level1这个特征图上被检测到的，并且观察level1这一层的权重信息<script type="math/tex">\alpha, \beta, \gamma</script>可以发现，对于图中斑马这种大目标更容易被高层的特征捕捉到，因为对于大物体需要更大的感受野和高级语义特征。而对于小目标的检测，可以看到羊更多的是被level2和level3检测到，这也说明了对于小物体更需要底层特征中的细粒度特征来检测。</p>
<h3 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h3><ol>
<li><a target="_blank" rel="noopener" href="https://qiyuan-z.github.io/2020/04/20/%E8%87%AA%E9%80%82%E5%BA%94%E7%A9%BA%E9%97%B4%E7%89%B9%E5%BE%81%E8%9E%8D%E5%90%88-(ASFF)/">https://qiyuan-z.github.io/2020/04/20/%E8%87%AA%E9%80%82%E5%BA%94%E7%A9%BA%E9%97%B4%E7%89%B9%E5%BE%81%E8%9E%8D%E5%90%88-(ASFF)/</a></li>
<li><a target="_blank" rel="noopener" href="https://www.cnblogs.com/wujianming-110117/p/12921308.html">https://www.cnblogs.com/wujianming-110117/p/12921308.html</a></li>
<li><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/129363523">https://zhuanlan.zhihu.com/p/129363523</a></li>
<li><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/138816612">https://zhuanlan.zhihu.com/p/138816612</a></li>
</ol>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://example.com/2021/12/21/letterbox/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="wyukai">
      <meta itemprop="description" content="do">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="yukai">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2021/12/21/letterbox/" class="post-title-link" itemprop="url">YOLOv5 自适应图片缩放</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2021-12-21 14:32:38" itemprop="dateCreated datePublished" datetime="2021-12-21T14:32:38+08:00">2021-12-21</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2021-12-28 16:06:14" itemprop="dateModified" datetime="2021-12-28T16:06:14+08:00">2021-12-28</time>
              </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h3 id="自适应图片缩放"><a href="#自适应图片缩放" class="headerlink" title="自适应图片缩放"></a>自适应图片缩放</h3><p>按照以往的经验，目标检测算法在训练和推理阶段都会resize到统一的图像尺寸，YOLOv5在推理阶段采用了自适应的图片缩放trick。</p>
<p><img src="../images/letterbox/format,png.png" alt="img"></p>
<p>在YOLOv5 官方github下有这样一段解释，采用32整数倍的矩形框推理要比resize到等长宽的正方形进行推理的时间减少很多（416 ,416)-&gt;(256 , 416）。</p>
<h3 id="训练阶段"><a href="#训练阶段" class="headerlink" title="训练阶段"></a>训练阶段</h3><p>假设原图尺寸为（523， 699）</p>
<p>（1） 计算长边缩放比例 r = 416 / 699 = 0.5951</p>
<p>（2）将原图等比例缩放 (523，699) —&gt;&gt;  (311, 416)</p>
<p><img src="../images/letterbox/image-20211221174250645.png" alt="image-20211221174250645"></p>
<p>（3） 填充为（416，416），H侧上下需要填充的大小 pad = (416 - 311) / 2 = 52.5</p>
<p><img src="../images/letterbox/new-16400798041612.jpg" alt="new"></p>
<h3 id="推理阶段"><a href="#推理阶段" class="headerlink" title="推理阶段"></a>推理阶段</h3><p>（1） 计算长边缩放比例 r = 416 / 699 = 0.5951</p>
<p>（2）将原图等比例缩放 (523，699) —&gt;&gt;  (311, 416)</p>
<p>（3）原始输入图像缩放后的分辨率（设定为32的倍数）： np.ceil(0.5951 x 523 / 32) x 32,   np.ceil(1 x 699 / 32) x 32 =  (320,416)</p>
<p>（4）计算需要的padding,   宽 padding = (416 - 416) / 2 = 0,     高padding  =  (320 -  311) / 2 = 4.5  (top  4 ,   bottom 5) </p>
<p>（5）填充像素值  （144，144，144）灰色像素</p>
<p>所以推理阶段的分辨率为（320，416）， 在保证图像不失真的情况下，可以显著减少计算量，加快推理速度。</p>
<p><img src="../images/letterbox/new-16400808257133.jpg" alt="new"></p>
<h3 id="code"><a href="#code" class="headerlink" title="code"></a>code</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> cv2 <span class="keyword">as</span> cv</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">letterbox</span>(<span class="params">im, new_shape, color=(<span class="params"><span class="number">140</span>,<span class="number">140</span>,<span class="number">140</span></span>), stride=<span class="number">32</span>, auto=<span class="literal">True</span></span>):</span></span><br><span class="line">    shape = im.shape[:<span class="number">2</span>] <span class="comment"># current shape [height, width]</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># calculate scale ratio r</span></span><br><span class="line">    r = <span class="built_in">min</span>(new_shape[<span class="number">0</span>] / shape[<span class="number">0</span>], new_shape[<span class="number">1</span>] / shape[<span class="number">1</span>])</span><br><span class="line"></span><br><span class="line">    <span class="comment"># compute padding   new_unpad : [w, h]</span></span><br><span class="line">    new_unpad = <span class="built_in">int</span>(<span class="built_in">round</span>(shape[<span class="number">1</span>] * r)), <span class="built_in">int</span>(<span class="built_in">round</span>(shape[<span class="number">0</span>] * r))</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;new_unpad::&#x27;</span>,new_unpad)</span><br><span class="line">    dw = new_shape[<span class="number">1</span>] - new_unpad[<span class="number">0</span>]</span><br><span class="line">    dh = new_shape[<span class="number">0</span>] - new_unpad[<span class="number">1</span>]</span><br><span class="line">   </span><br><span class="line">    <span class="comment"># minimum rectangle</span></span><br><span class="line">    <span class="keyword">if</span> auto:</span><br><span class="line">        dw = np.mod(dw, stride)</span><br><span class="line">        dh = np.mod(dh, stride)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># dw dh for every side</span></span><br><span class="line">    dw /= <span class="number">2</span></span><br><span class="line">    dh /= <span class="number">2</span></span><br><span class="line">    </span><br><span class="line">   </span><br><span class="line">    <span class="keyword">if</span> shape[::-<span class="number">1</span>] != new_unpad: </span><br><span class="line">        im = cv.resize(im, new_unpad, interpolation=cv.INTER_LINEAR)</span><br><span class="line">    <span class="comment"># padding   if dw &lt; 1： dw = 0</span></span><br><span class="line">    top, bottom = <span class="built_in">int</span>(<span class="built_in">round</span>(dh - <span class="number">0.1</span>)), <span class="built_in">int</span>(<span class="built_in">round</span>(dh + <span class="number">0.1</span>))</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;top&#x27;</span>,top, bottom)</span><br><span class="line">    left, right = <span class="built_in">int</span>(<span class="built_in">round</span>(dw - <span class="number">0.1</span>)), <span class="built_in">int</span>(<span class="built_in">round</span>(dw + <span class="number">0</span>,<span class="number">1</span>))</span><br><span class="line"></span><br><span class="line">    im = cv.copyMakeBorder(im, top,bottom,left,right, cv.BORDER_CONSTANT, value=color)</span><br><span class="line">    </span><br><span class="line">    <span class="built_in">print</span>(im.shape)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> im, r, (dw, dh)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    img_path = <span class="string">&quot;D:\\person\\py_code\\list\\R-C.png&quot;</span></span><br><span class="line">    img = cv.imread(img_path)</span><br><span class="line"></span><br><span class="line">    im, r, _ = letterbox(img, (<span class="number">416</span>,<span class="number">416</span>))</span><br><span class="line">    </span><br><span class="line">    <span class="built_in">print</span>(r)</span><br><span class="line">    cv.imwrite(<span class="string">&#x27;D:\\person\\py_code\\list\\new.jpg&#x27;</span>, im)</span><br><span class="line"></span><br></pre></td></tr></table></figure>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://example.com/2021/12/10/C-%E7%BA%BF%E7%A8%8B%E9%94%81/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="wyukai">
      <meta itemprop="description" content="do">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="yukai">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2021/12/10/C-%E7%BA%BF%E7%A8%8B%E9%94%81/" class="post-title-link" itemprop="url">C++线程锁</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>
              

              <time title="创建时间：2021-12-10 14:01:56 / 修改时间：14:17:42" itemprop="dateCreated datePublished" datetime="2021-12-10T14:01:56+08:00">2021-12-10</time>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h2 id="C-11中的几种线程锁"><a href="#C-11中的几种线程锁" class="headerlink" title="C++11中的几种线程锁"></a>C++11中的几种线程锁</h2><p>线程之间的锁有： 互斥锁，条件锁，自旋锁，读写锁，递归锁。一般情况下，锁的功能是与程序性能成反比。</p>
<ol>
<li><p>互斥锁（Mutex）</p>
<p>互斥锁用于控制多个线程对他们之间共享资源互斥访问的一个信号量，为了避免多个线程在某一时刻同时操作一个共享资源。例如线程池中的有多个空闲线程和一个任务队列。任何是一个线程都要使用互斥锁互斥访问任务队列，以避免多个线程同时访问任务队列以发生错乱。在某一时刻，只有一个线程可以获取互斥锁，在释放互斥锁之前其他线程都不能获取该互斥锁。如果其他线程想要获取这个互斥锁，那么这个线程只能以阻塞方式进行等待。</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;list&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;mutex&gt;</span></span></span><br><span class="line"></span><br><span class="line">std::list&lt;<span class="keyword">int</span>&gt; some_list;</span><br><span class="line">std::mutex some_mutex;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">add_to_list</span><span class="params">(<span class="keyword">int</span> new_value)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="function">std::lock_guard&lt;std::mutex&gt; <span class="title">guard</span><span class="params">(some_mutex)</span></span>;</span><br><span class="line">    some_list.<span class="built_in">push_back</span>(new_value);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
</li>
</ol>
<ol>
<li><p>条件锁</p>
<p>条件锁就是所谓的条件变量，某一个线程因为某个条件为满足时可以使用条件变量使改程序处于阻塞状态。一旦条件满足以“信号量”的方式唤醒一个因为该条件而被阻塞的线程。最为常见就是在线程池中，起初没有任务时任务队列为空，此时线程池中的线程因为“任务队列为空”这个条件处于阻塞状态。一旦有任务进来，就会以信号量的方式唤醒一个线程来处理这个任务。</p>
</li>
<li><p>自旋锁</p>
<p>假设我们有一个两个处理器core1和core2计算机，现在在这台计算机上运行的程序中有两个线程：T1和T2分别在处理器core1和core2上运行，两个线程之间共享着一个资源。</p>
<p>互斥锁是是一种sleep-waiting的锁。假设线程T1获取互斥锁并且正在core1上运行时，此时线程T2也想要获取互斥锁（pthread_mutex_lock），但是由于T1正在使用互斥锁使得T2被阻塞。当T2处于阻塞状态时，T2被放入到等待队列中去，处理器core2会去处理其他任务而不必一直等待（忙等）。也就是说处理器不会因为线程阻塞而空闲着，它去处理其他事务去了。</p>
<p>而自旋锁就不同了，自旋锁是一种busy-waiting的锁。也就是说，如果T1正在使用自旋锁，而T2也去申请这个自旋锁，此时T2肯定得不到这个自旋锁。与互斥锁相反的是，此时运行T2的处理器core2会一直不断地循环检查锁是否可用（自旋锁请求），直到获取到这个自旋锁为止。</p>
<p>从“自旋锁”的名字也可以看出来，如果一个线程想要获取一个被使用的自旋锁，那么它会一致占用CPU请求这个自旋锁使得CPU不能去做其他的事情，直到获取这个锁为止，这就是“自旋”的含义。</p>
<p>当发生阻塞时，互斥锁可以让CPU去处理其他的任务；而自旋锁让CPU一直不断循环请求获取这个锁。通过两个含义的对比可以我们知道“自旋锁”是比较耗费CPU的。</p>
</li>
<li><p>读写锁 </p>
<p>借助于“读者-写者”问题进行理解， 计算机中某些数据被多个进程共享，对数据库的操作有两种：一种是读操作，就是从数据库中读取数据不会修改数据库中内容；另一种就是写操作，写操作会修改数据库中存放的数据。因此可以得到我们允许在数据库上同时执行多个“读”操作，但是某一时刻只能在数据库上有一个“写”操作来更新数据。这就是一个简单的读者-写者模型。</p>
</li>
</ol>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  


  
  <nav class="pagination">
    <span class="page-number current">1</span><a class="page-number" href="/page/2/">2</a><a class="extend next" rel="next" href="/page/2/"><i class="fa fa-angle-right" aria-label="下一页"></i></a>
  </nav>



          </div>
          

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <p class="site-author-name" itemprop="name">wyukai</p>
  <div class="site-description" itemprop="description">do</div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">18</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/categories/">
          
        <span class="site-state-item-count">8</span>
        <span class="site-state-item-name">分类</span></a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/tags/">
          
        <span class="site-state-item-count">4</span>
        <span class="site-state-item-name">标签</span></a>
      </div>
  </nav>
</div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2022</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">wyukai</span>
</div>
  <div class="powered-by">由 <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> & <a href="https://theme-next.org/" class="theme-link" rel="noopener" target="_blank">NexT.Gemini</a> 强力驱动
  </div>

        








      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/pisces.js"></script>


<script src="/js/next-boot.js"></script>




  















  

  

  

</body>
</html>
