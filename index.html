<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 5.4.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/all.min.css">

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"example.com","root":"/","scheme":"Gemini","version":"7.8.0","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":false,"show_result":false,"style":null},"back2top":{"enable":true,"sidebar":false,"scrollpercent":false},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":false,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}}};
  </script>

  <meta name="description" content="do">
<meta property="og:type" content="website">
<meta property="og:title" content="yukai">
<meta property="og:url" content="http://example.com/index.html">
<meta property="og:site_name" content="yukai">
<meta property="og:description" content="do">
<meta property="og:locale" content="zh_CN">
<meta property="article:author" content="wyukai">
<meta name="twitter:card" content="summary">

<link rel="canonical" href="http://example.com/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : true,
    isPost : false,
    lang   : 'zh-CN'
  };
</script>

  <title>yukai</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">yukai</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-home fa-fw"></i>首页</a>

  </li>
        <li class="menu-item menu-item-about">

    <a href="/about/" rel="section"><i class="fa fa-user fa-fw"></i>关于</a>

  </li>
        <li class="menu-item menu-item-tags">

    <a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>标签</a>

  </li>
        <li class="menu-item menu-item-categories">

    <a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>分类</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>归档</a>

  </li>
  </ul>
</nav>




</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content index posts-expand">
            
      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://example.com/2021/10/25/AdaFocus/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="wyukai">
      <meta itemprop="description" content="do">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="yukai">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2021/10/25/AdaFocus/" class="post-title-link" itemprop="url">AdaFocus算法记录</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>
              

              <time title="创建时间：2021-10-25 14:13:33 / 修改时间：15:46:27" itemprop="dateCreated datePublished" datetime="2021-10-25T14:13:33+08:00">2021-10-25</time>
            </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/deep-learning/" itemprop="url" rel="index"><span itemprop="name">deep learning</span></a>
                </span>
                  ，
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/deep-learning/object-detection/" itemprop="url" rel="index"><span itemprop="name">object detection.</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <p>转载自：计算机视觉Daily，个人学习记录</p>
<h2 id="1-简介"><a href="#1-简介" class="headerlink" title="1. 简介"></a>1. 简介</h2><p>AdaFocus为被ICCV-2021会议录用为Oral Presentation的一篇文章：Adaptive Focus for Efficient Video Recognition。 其从空间特征角度出发，从降低空间冗余性来实现高效视频识别。</p>
<p>现有高效视频识别算法往往关注于降低视频的时间冗余性（即将计算集中于视频的部分关键帧），如图1 (b)。本文则发现，降低视频的空间冗余性（即寻找和重点处理视频帧中最关键的图像区域），如图1 (c)，同样是一种效果显著、值得探索的方法；且后者与前者有效互补（即完全可以同时建模时空冗余性，例如关注于关键帧中的关键区域），如图1 (d)。在方法上，本文提出了一个通用于大多数网络的AdaFocus框架，在同等精度的条件下，相较AR-Net (ECCV-2020)将计算开销降低了2.1-3.2倍，将TSM的GPU实测推理速度加快了1.4倍。</p>
<p><img src="../images/AdaFocus/image-20211025143754892.png" alt="image-20211025143754892"></p>
<ul>
<li>论文：<a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2105.03245.pdf">https://arxiv.org/pdf/2105.03245.pdf</a></li>
<li>Code：<a target="_blank" rel="noopener" href="https://github.com/blackfeather-wang/AdaFocus">https://github.com/blackfeather-wang/AdaFocus</a></li>
<li>B站介绍：<a target="_blank" rel="noopener" href="https://www.bilibili.com/video/BV1vb4y1a7sD/">https://www.bilibili.com/video/BV1vb4y1a7sD/</a></li>
<li>作者个人网站：<a target="_blank" rel="noopener" href="https://www.rainforest-wang.cool/">https://www.rainforest-wang.cool/</a></li>
</ul>
<h2 id="2-研究动机"><a href="#2-研究动机" class="headerlink" title="2. 研究动机"></a>2. 研究动机</h2><p>相较于图像，视频识别是一个分布范围更广、应用场景更多的任务。如下图所示，每分钟，即有超过300小时的视频上传至YouTube；至2022年，超过82%的消费互联网流量将由在线视频组成。自动识别这些海量视频中的人类行为、事件、紧急情况等内容，对于视频推荐、监控等受众广泛的实际应用具有重要意义。</p>
<p><img src="../images/AdaFocus/image-20211025143955391.png" alt="image-20211025143955391"></p>
<p>近年来，已有很多基于深度学习的视频识别算法取得了较佳的性能，如TSM、SlowFast、I3D等。然而，一个严重的问题是，相较于图像，使用深度神经网络处理视频通常会引入很大的计算开销。如下图所示，将ResNet-50应用于视频识别将使运算量（FLOPs）扩大8-75倍。</p>
<p><img src="../images/AdaFocus/image-20211025144020950.png" alt="image-20211025144020950"></p>
<p>因此，一个关键问题在于，如何降低视频识别模型的计算开销。一个非常自然的想法是从视频的时间维度入手：一方面，相邻的视频帧之间往往具有较大的相似性，逐帧处理将引入冗余计算；另一方面，并非全部视频帧的内容都与识别任务相关。现有工作大多从这一时间冗余性出发，动态寻找视频中的若干关键帧进行重点处理，以降低计算成本，如下图所示。</p>
<p><img src="../images/AdaFocus/image-20211025144125135.png" alt="image-20211025144125135"></p>
<p>但是，值得注意的一点是，我们发现，目前尚未有工作关注于视频中的空间冗余性。具体而言，在每一帧视频中，事实上只有一部分空间区域与识别任务相关，例如下图中的运动员、起跳动作、水花等。</p>
<p><img src="../images/AdaFocus/image-20211025144147038.png" alt="image-20211025144147038"></p>
<p>出于这一点，本文以回答图6中的两个问题作为主线：</p>
<ul>
<li><ol>
<li><strong>空间冗余性是否可以用于实现高效视频识别？</strong>假如我们能找到每一视频帧中的关键区域，并将主要的计算集中于这些更有价值的部分，而尽可能略过其他任务相关信息较少的区域，理论上，我们就可以显著降低网络的计算开销（事实上，我们之前基于单张图像验证过类似做法的效果：NeurIPS 2020 | Glance and Focus: 通用、高效的神经网络自适应推理框架：<a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/266306870）。">https://zhuanlan.zhihu.com/p/266306870）。</a></li>
<li><strong>空间、时间冗余性是否互补？</strong>若上述假设成立的话，它应当可与现存的、基于时间冗余性的工作相结合，因为我们完全可以先找到少数关键帧，再仅在这些帧中寻找关键的图像区域进行重点处理。</li>
</ol>
</li>
</ul>
<p><img src="../images/AdaFocus/image-20211025144336382.png" alt="image-20211025144336382"></p>
<h2 id="3-核心思想"><a href="#3-核心思想" class="headerlink" title="3. 核心思想"></a>3. 核心思想</h2><p>首先为了回答问题1，作者设计了一个AdaFocus框架，其结构如下图所示。</p>
<p><img src="../images/AdaFocus/image-20211025144442968.png" alt="image-20211025144442968"></p>
<p>此处我们假设视频帧按时间次序逐个输入网络，AdaFocus使用四个组件对其进行处理。</p>
<ol>
<li>全局CNN   <script type="math/tex">f(G)</script>  （Global CNN）是一个轻量化的卷积网络（例如MobileNet-V2)，用于以低成本对每一帧视频进行粗略处理，获取其空间分布信息。</li>
<li>策略网络 <script type="math/tex">\pi</script>（Policy Network）是一个循环神经网络（RNN），以<script type="math/tex">f(g)</script>的提取出的特征图作为输入，用于整合到目前为止所有视频帧的信息，进而决定当前帧中包含最重要信息的一个图像小块（patch）的位置。值得注意的是由于取得patch的crop操作不可求导，<script type="math/tex">\pi</script>是使用强化学习中的策略梯度方法（policy gradient)训练的。</li>
<li>局部CNN<script type="math/tex">f(L)</script>（Local CNN）是一个容量大、准确率高但参数量和计算开销较大的卷积网络（例如ResNet），仅处理策略网络<script type="math/tex">\pi</script> 选择出的局部patch，由于patch的空间尺寸小于原图，处理其的计算开销显著低于处理整个视频帧。</li>
<li>分类器<script type="math/tex">f(c)</script>（Classifier）为另一个循环神经网络（RNN），输入为<script type="math/tex">f(G)</script>和 <script type="math/tex">f(L)</script>输出特征的并联，用于整合过去所有视频帧的信息，以得到目前最优的识别结果<script type="math/tex">p_t</script>（t表示帧序号)。</li>
</ol>
<h2 id="4-主要贡献点"><a href="#4-主要贡献点" class="headerlink" title="4. 主要贡献点"></a>4. 主要贡献点</h2><p>（1）在现有的基于时间冗余性的方法之外，思考利用空间冗余性实现高效视频识别；</p>
<p>（2）基于强化学习，提出了一种在理论上和实测速度上效果都比较明显的通用框架，AdaFocus；</p>
<p>（3）在五个数据集上进行了实验，包括与其他通用框架的比较和部署于现有高效识别网络（例如TSM）上的效果等。</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://example.com/2021/10/22/%E6%97%A5%E5%B8%B8%E8%AE%B0%E5%BD%95/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="wyukai">
      <meta itemprop="description" content="do">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="yukai">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2021/10/22/%E6%97%A5%E5%B8%B8%E8%AE%B0%E5%BD%95/" class="post-title-link" itemprop="url">日常记录</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>
              

              <time title="创建时间：2021-10-22 14:36:24 / 修改时间：14:48:38" itemprop="dateCreated datePublished" datetime="2021-10-22T14:36:24+08:00">2021-10-22</time>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <ul>
<li>Papers with Codes 是一个总结了机器学习论文及其代码实现的网站，这个网站最好的地方就是对机器学习做了任务分类，检索对应的模型非常方便。<ul>
<li>地址：<a target="_blank" rel="noopener" href="https://links.jianshu.com/go?to=https://paperswithcode.com">https://paperswithcode.com</a></li>
</ul>
</li>
</ul>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://example.com/2021/10/20/FixMatch/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="wyukai">
      <meta itemprop="description" content="do">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="yukai">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2021/10/20/FixMatch/" class="post-title-link" itemprop="url">FixMatch算法记录</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2021-10-20 18:00:00" itemprop="dateCreated datePublished" datetime="2021-10-20T18:00:00+08:00">2021-10-20</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2021-10-25 15:47:25" itemprop="dateModified" datetime="2021-10-25T15:47:25+08:00">2021-10-25</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/deep-learning/" itemprop="url" rel="index"><span itemprop="name">deep learning</span></a>
                </span>
                  ，
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/deep-learning/object-detection/" itemprop="url" rel="index"><span itemprop="name">object detection.</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h2 id="1-简介"><a href="#1-简介" class="headerlink" title="1. 简介"></a>1. 简介</h2><p>&emsp;&emsp;深度学习在具体的商业落地场景中需要依赖于海量的数据。算法，算力，数据是驱动Deep Learning 运行的三大动力， 而数据又是其中重要影响因素，模型效果80%靠数据，20%靠算法。在工业场景中，面对众多非标准化产品，频繁更换型号的场景，进行数据标准的成本是巨大的，而且客户对某一款产品的算法落地时间有限制， 且如果模型对相似型号的兼容性较差，也会引起客户对AI方案的不信任。</p>
<hr>
<p>&emsp;&emsp;在此种背景下，如何利用大量未标注的图像以及部分已标注的图像来提高模型的性能就变得尤为重要。其中，半监督学习（SSL）就是一种值得尝试的方案，Fix-Match, 是谷歌Google Brain 提出的一种半监督学习方法，对于解决数据收集困难，标注成本高的CV问题会有一定的帮助。</p>
<ul>
<li>FixMatch： Simplifying Semi-Supervised Learning with Consistency and Confidence</li>
<li>主要贡献： 利用一致性正则化（ Consistency regularization）和伪标签（pseudo-labeling）技术进行无监督训练。SOTA 精度，其中CIFAR-10有250个标注，准确率为94.93%。甚至仅使用10张带有标注的图在CIFAR-10上达到78％精度。</li>
<li>论文： <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2001.07685">https://arxiv.org/abs/2001.07685</a></li>
<li>code： <a target="_blank" rel="noopener" href="https://github.com/google-research/fixmatch">https://github.com/google-research/fixmatch</a></li>
</ul>
<h2 id="2-半监督学习"><a href="#2-半监督学习" class="headerlink" title="2. 半监督学习"></a>2. 半监督学习</h2><p>​        半监督学习（Semi-supervised learning）是一种学习方法，其使用少量标记的数据和大量未标记的数据进行学习。相对于监督学习（Supervised Learning）而言，最大的优势是无需为所有数据准备标签。</p>
<p>​        FixMatch使用的数据集也为带所有标注的数据集，如CIFAR-10， 因为算法训练的要求，需要姜训练数据中的一部分标签删掉， 换句话说，其训练数据为一部分有标签数据 + 一部分无标签数据。</p>
<h2 id="3-核心思想"><a href="#3-核心思想" class="headerlink" title="3. 核心思想"></a>3. 核心思想</h2><p><img src="/images/FixMatch/v2-21388836987e72bff390f7f4a3ade136_r.jpg" alt="v2-21388836987e72bff390f7f4a3ade136_r"></p>
<ol>
<li>整体分为两个部分， 有监督训练部分和无监督训练部分。</li>
</ol>
<ul>
<li>监督训练部分， 利用labeled数据进行监督训练，得到Model A</li>
<li>无监督训练部分， 首先由原图生成<strong>弱增强</strong>数据，通过Model A获得<strong>伪标签</strong>（pseudo-label）, 然后使用<strong>交叉熵损失</strong>利用该伪标签去监督<strong>强增强</strong>的输出值， 特别地，FixMatch仅使用具有<strong>高置信度</strong>的未标记样本参与无监督训练部分。</li>
</ul>
<ol>
<li>无监督训练部分包含两种策略，<strong>一致性正则化及伪标签训练</strong>。</li>
</ol>
<ul>
<li>一致性正则化是当前半监督SOTA工作中一个重要的组件，其建立在一个基本假设：相同图片经过不同扰动（增强）经过网络会输出相同预测结果，FixMatch是对弱增强图像与强增强图像之间的进行一致性正则化，但是其没有使用两种图像的概率分布一致，而是使用弱增强的数据制作了伪标签，这样就自然需要使用交叉熵进行一致性正则化了。</li>
<li>伪标签是利用模型本身为未标记数据获取人工标签的思想。通常是使用“hard”标签，也就是argmax获取的onehot标签，仅保留最大类概率超过阈值的标签。</li>
</ul>
<p><strong>3. Why Work ?</strong></p>
<p>​        无监督训练过程实际上是一个孪生网络，可以提取到图片的有用特征。弱增强不至于图像失真，再加上输出伪标签阈值的设置，极大程度上降低了引入错误标签噪声的可能性。而仅仅使用弱增强可能会导致训练过拟合，无法提取到本质的特征，所以使用强增强。强增强带来图片的严重失真，但是依然是保留足够可以辨认类别的特征。有监督和无监督混合训练，逐步提高模型的表达能力。</p>
<h2 id="4-细节"><a href="#4-细节" class="headerlink" title="4. 细节"></a>4. 细节</h2><ol>
<li>数据增强方式<ul>
<li>弱增强：用标准的翻转和平移策略， 50%的概率进行flip和12.5%的概率进行shift，包括水平和竖直方向。</li>
<li>强增强：输出严重失真的输入图像，先使用RandAugment 或 CTAugment，再使用 CutOut 增强</li>
</ul>
</li>
<li>网络模型<ul>
<li>FixMatch使用 Wide-Resnet 变体作为基础体系结构，记为 Wide-Resnet-28-2，其深度为 28，扩展因子为 2。因此，此模型的宽度是 ResNet 的两倍。</li>
</ul>
</li>
<li>算法流程</li>
</ol>
<p><img src="/images/FixMatch/image-20211022153823958.png" alt="image-20211022153823958"></p>
<p>（1）Input：准备了batch=B的有标签数据和batch=μB 的无标签数据，其中μ是无标签数据的比例；</p>
<p>（2）监督训练：对于在标注数据的监督训练，将常规的交叉熵损失 H()用于分类任务。有标签数据的损失记为ls，如伪代码中第2行所示；</p>
<p>（3）生成伪标签：对无标签数据分别应用弱增强和强增强得到增强后的图形，再送给模型得到预测值，并将弱增强对应的预测值通过 argmax 获得伪标签；</p>
<p>（4）一致性正则化：将强增强对应的预测值与弱增强对应的伪标签进行交叉熵损失 H()计算，未标注数据的损失由 lu 表示，如伪代码中的第7行所示；式τ表示伪标签的阈值；</p>
<p>（5）完整损失函数：最后，我们将ls和lu损失相结合，如伪代码第8行所示，对其进行优化以改进模型，其中，λu 是未标记数据对应损失的权重。</p>
<h2 id="5-实验结果"><a href="#5-实验结果" class="headerlink" title="5. 实验结果"></a>5. 实验结果</h2><p>作者分别在CIFAR和SVHM等数据集上进行了训练测试，模型表现超过之前的网络。具体如下：</p>
<p><img src="/images/FixMatch/image-20211022154528429.png" alt="image-20211022154528429"></p>
<ol>
<li>对于极端缺少标注的场景，仅仅使用每个类别1张共10张标注的图片就可以达到78%的最大accuracy，当然这种做法和挑选的样本质量有关，作者也做了相关实验论证。不过也证明本文的方法的确work。</li>
</ol>
<p><img src="/images/FixMatch/image-20211022154712637.png" alt="image-20211022154712637"></p>
<ol>
<li><p>另外还有一些具体的调参实验，总的来说，通过FixMatch，我们可以得到以下结论：</p>
<p>（1）使用具有高置信度的未标记数据参与训练效果比较好(Argmax)；</p>
<p>（2）适当增加batch中未标记数据的比例有助于提高识别精度；</p>
<p>（3）T越小（即分布越尖锐），则精度会越高(Sharppen Method)。</p>
<p>总的来说，半监督学习是一种好方法，因为其是一种可以在开始高成本之前使用的方法。</p>
</li>
</ol>
<h1 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h1><ul>
<li>FixMAtch是半监督领域的一篇经典论文，其做法简单有效，使用图像增强技术进行伪标签学习和一致性正则化训练，在CIFAR等多个数据集上仅仅利用少量的标注图片就可以达到一个不错的效果，这对于获取标注困难的场景非常有意义。例如在工业应用领域，可能会有海量数据，但是现实限制可能无法都进行人工标注，因此可以尝试利用半监督训练的方法，非常值得借鉴。</li>
<li><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/165337501">https://zhuanlan.zhihu.com/p/165337501</a></li>
<li><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/422930830">https://zhuanlan.zhihu.com/p/422930830</a></li>
<li><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/340474319">https://zhuanlan.zhihu.com/p/340474319</a></li>
</ul>
<p>个人记录学习</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://example.com/2021/10/20/FlexMatch/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="wyukai">
      <meta itemprop="description" content="do">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="yukai">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2021/10/20/FlexMatch/" class="post-title-link" itemprop="url">FlexMatch算法记录</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2021-10-20 18:00:00" itemprop="dateCreated datePublished" datetime="2021-10-20T18:00:00+08:00">2021-10-20</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2021-10-22 18:04:03" itemprop="dateModified" datetime="2021-10-22T18:04:03+08:00">2021-10-22</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/deep-learning/" itemprop="url" rel="index"><span itemprop="name">deep learning</span></a>
                </span>
                  ，
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/deep-learning/object-detection/" itemprop="url" rel="index"><span itemprop="name">object detection.</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <p>转载自 知乎 NeurIPS 2021 | 助力半监督学习：课程伪标签方法FlexMatch和统一开源库TorchSSL 作者 王晋东不在家     </p>
<h2 id="1-简介"><a href="#1-简介" class="headerlink" title="1. 简介"></a>1. 简介</h2><p>FlexMatch为FixMatch的改进版， 第一作者为日本东京工业大学的张博闻和王一栋，其他作者来自东京工业大学和微软亚洲研究院。文章针对半监督提出了 <strong>课程伪标签(Curriculum Pseudo Labeling, CPL)</strong> 的方法，其能被简单地应用到多个半监督方法上，且<strong>不会</strong>引入新的超参数和额外的计算开销。多项实验证明，CPL不仅能提升已有方法的精度，也能大幅提升收敛速度（例如，在一些数据集上比Google的FixMatch快5倍）。特别地，文章中将CPL应用在FixMatch后的新算法命名为<strong>FlexMatch</strong>， 并在多个图像分类数据集上取得了state-of-the-art的效果。除此之外，本文还开源了一个统一的基于Pytorch的<strong>半监督方法库TorchSSL</strong>，公平地实现了诸多流行的半监督方法，方便相关领域进行进一步研究。</p>
<ul>
<li><p>论文标题：FlexMatch: Boosting Semi-Supervised Learning with Curriculum Pseudo Labeling</p>
</li>
<li><p>论文地址：<a href="https://link.zhihu.com/?target=http://arxiv.org/abs/2110.08263">http://arxiv.org/abs/2110.0826</a></p>
</li>
<li><p>代码地址：<a href="https://link.zhihu.com/?target=https://github.com/TorchSSL/TorchSSL">https://github.com/TorchSSL/TorchSSL</a></p>
<p><img src="/images/FlexMatch/image-20211022163508349.png" alt="image-20211022163508349"></p>
</li>
</ul>
<hr>
<h2 id="2-核心思想"><a href="#2-核心思想" class="headerlink" title="2. 核心思想"></a>2. 核心思想</h2><p>SSL学习方法常使用伪标签作为未标注数据的标签，随着模型训练而产生的伪标签往往伴随着大量错误标注，很多算法因此设定了一个高而固定的阈值$\tau$，来选取那些置信度高的伪标签去计算无监督损失。高阈值可以有效地降低确认偏差(confirmation bias)，过滤有噪数据。但这种固定高阈值存在一定的问题。</p>
<ul>
<li><p>对于分类任务而言，<strong>不同的类别的学习难度是不同的，模型在某一时刻对各类的学习情况也是不同的。</strong>学的比较好的类，或是简单的类，置信度自然会比较高，就更容易被固定阈值选取。而那些困难的类别，或是当下学的不是很好的类，由于置信度会偏低，就不容易被选到。这样就会导致模型有点“偏科”。表现到模型上就是：<strong>对困难类别的拟合不会很好，导致困难类别的最终精度不会很高</strong>， 如图是FixMatch和FlexMatch的各类学习效果对比</p>
<p><img src="/images/FlexMatch/image-20211022164122042.png" alt="image-20211022164122042"></p>
<ul>
<li><p>在训练的起步阶段，受随机初始化影响，模型很可能把数据都<strong>盲目地预测到一个类</strong>里面去并且信心很高。如果一个batch中，只选出了这样错误的高信心伪标签，就会把模型往一个错误的方向优化。同时，即便一些样本的预测是正确的，由于开始阶段普遍置信度偏低，导致每个batch的<strong>数据利用率不高</strong>（大部分被过滤掉了），也会导致收敛很慢。如图是FixMatch和FlexMatch的收敛速度对比。</p>
<p><img src="/images/FlexMatch/image-20211022164131971.png" alt="image-20211022164131971"></p>
</li>
</ul>
</li>
</ul>
<p>​        为了解决第一个问题，作者引入了课程学习的思想，把单独的固定阈值转化成了<strong>逐类的动态阈值，根据类别难度给每个类不同的阈值，且这些阈值可以随着模型的学习情况进行实时调整。</strong>****</p>
<p>​       针对第二个问题，作者引入了阈值的warm-up。其思想是，前期由于置信度不是很可靠，我们并不完全根据置信度来选样本，而是让<strong>所有类的阈值逐渐从0开始上升</strong>，给所有样本一个被学习的机会，等模型逐渐稳定获得辨识能力后再恢复到设计的动态阈值，其思想类似学习率的warm-up，因此叫threshold warm-up。</p>
<h2 id="3-细节"><a href="#3-细节" class="headerlink" title="3. 细节"></a>3. 细节</h2><p>各类的动态阈值是如何设计的呢？一个最简单的想法是通过类别准确率(class-wise accuracy)来确定。即：降低准确率更低的类的阈值，给这些类的数据更多被学习的机会，以让模型更好地拟合这些类。而对于准确率已经很高的类，就保持高阈值，以确保最终的精度。</p>
<p><img src="/images/FlexMatch/image-20211022172533688.png" alt="image-20211022172533688"></p>
<p>这是一个很理想的方法，但是却存在一些问题。这种方式需要一个<strong>额外的有标签的验证集</strong>来评价各类的准确率，这在半监督学习下是一笔昂贵的开销，因为我们的标记数据已经很少了。其次， 这种方式需要<strong>引入大量的额外计算</strong>，因为要想实时调整动态阈值，需要在每一步迭代后都做一个额外的前向传播来计算类别准确率。这会大幅降低算法速度。而CPL用了一种巧妙且简单的方法，使得既不需要额外验证集，也不引入额外计算，还不增加额外的超参数。</p>
<p>​      从Figure 1中中左侧可以看到CPL考虑了所有的类的所有历史时刻的样本的置信度，对每个类会统计所有超过$\tau$的样本数量，其中 $\tau$ 就是前文提到的FixMatch中使用的固定高阈值，将统计出的数量作为学习效果预估(estimated learning effect)，并最终用其来调整动态阈值。这其中的关键假设是：<strong>当阈值足够高的时候，高于该阈值且落入类别c的样本个数可以大致反映类别c的学习效果</strong>。换句话说就是如果按FixMatch的算法来走，被选中样本越多的类学习效果就越好，反之亦然。这种设计的巧妙之处在于，FixMatch（UDA等算法同理)在训练的过程中就在选样本了，如果用他已经选出来的样本来调整动态阈值，那不就不需要额外的验证集，也不需要额外前向传播了吗。</p>
<p><strong>具体步骤：</strong></p>
<p><strong>Step1：学习效果预估</strong>， 如前文所述，这里$\sigma_t(c)$ 表示第<em>c</em>类在时刻$\tau$的预估学习效果，他其实就是在所有样本中对’高于固定阈值 $\tau$ ‘且’属于类别<em>c</em>的样本的一个计数*。</p>
<p><img src="/images/FlexMatch/image-20211022173349048.png" alt="image-20211022173349048"></p>
<p><strong>Step2：归一化。</strong> 由于预估学习效果是对样本的一个计数，他的大小会随数据集包含样本数而变，因此需要对其进行归一化使其范围在0到1之间。注意这里归一化分母不是所有类的统计的求和，而是取所有类预估学习效果中的最大值。这样做的特点是，学的最好的类的学习效果为1，进而在应用公式(7)后，其阈值变为 $\tau$ ，也是动态阈值的上限。</p>
<p><img src="/images/FlexMatch/image-20211022173432576.png" alt="image-20211022173432576"></p>
<p><strong>Step3：确定阈值？</strong> 这里的公式(7)其实已经可以作为最终的动态阈值了，然而作者又提出了两个tricks。</p>
<p><strong>Step2+：阈值预热。</strong> 如前文所述，文中引入了阈值预热来解决前期高确认偏差的问题。</p>
<p><img src="/images/FlexMatch/image-20211022173554481.png" alt="image-20211022173554481"></p>
<p>公式(11)改写了归一化公式(6)的分母部分，“学习效果最大值”改为“学习效果最大值 和 尚未被选择过的样本数 二者的最大值”，其中 $N - \sum_{c} \sigma_t $</p>
<p> 即表示目前尚未被高阈值选择过的样本数。前期，尚未被选择的样本数量占优，因此后项在起作用，随着大部分样本被选择过至少一次，前项起作用，公式(11)变得等价公式(7)。</p>
<p><strong>Step3+：非线性映射。</strong> 相比于公式(7)那样的直接scale固定阈值，非线性映射使得阈值的调整可以更加自由，你可以设计任意形状的函数来实现从“归一化预估学习效果$\beta_t(c)$”到“最终动态阈值$M(\beta_t(c))$”的映射。其中，本文提到，凸函数可能更加有效，因为凸函数在自变量较小时因变量的变化不是很大，而在自变量大时比较敏感。这比较符合预估学习效果的变化特性，即：前期当其值较小时可能存在较大波动而后期其值变大后波动较小，且中后期多处于较高的范围内变化，因此需要对这部分更敏感。</p>
<p><img src="/images/FlexMatch/image-20211022173825377.png" alt="image-20211022173825377"></p>
<h2 id="4-实验结果"><a href="#4-实验结果" class="headerlink" title="4. 实验结果"></a>4. 实验结果</h2><p>FlexMatch 在CIFAR10/100、SVHN、STL-10和ImageNet等常用数据集上进行了实验，对比了包括FixMatch、UDA、ReMixmatch等最新最强的SSL算法。实验结果如下表所示。</p>
<p><img src="/images/FlexMatch/image-20211022174103642.png" alt="image-20211022174103642"></p>
<p>可以看到CPL在多数数据集上取得了很大的提升，除了SVHN上效果不如原版FixMatch，文中的解释是说，CPL不适合<strong>数据分布不平衡且又很简单的任务</strong>，对于简单的任务而言，一个固定的高阈值似乎已经足够了。在其他数据集上，可以发现，<strong>标记数据越少，CPL带来的提升越大。任务越难，CPL的提升越大</strong>。文章同样在ImageNet数据集上测试了算法的有效性，在$2^{20}$ 次迭代后，应用了CPL的FlexMatch的top-1准确率已经比FixMatch高出将近8%了。证明在困难任务上的提升还是比较可观的，ImageNet的数据不平衡度应该和SVHN差不多，但是效果却差了很多。</p>
<h2 id="开源代码库TorchSSL"><a href="#开源代码库TorchSSL" class="headerlink" title="开源代码库TorchSSL"></a>开源代码库TorchSSL</h2><p>除此之外，本文开源了TorchSSL代码库，是第一个基于PyTorch的SSL算法库，目前已支持算法有：Pi-Model，MeanTeacher，Pseudo-Label，VAT，MixMatch，UDA，ReMixMatch，FixMatch，和我们的FlexMatch。</p>
<h2 id="5-References"><a href="#5-References" class="headerlink" title="5. References"></a>5. References</h2><ul>
<li><p><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/130244395">https://zhuanlan.zhihu.com/p/130244395</a></p>
</li>
<li><p>Dong-Hyun Lee et al. Pseudo-label: The simple and efficient semi-supervised learning methodfor deep neural networks. InWorkshop on challenges in representation learning, ICML,volume 3, 2013.</p>
</li>
<li><p> Qizhe Xie, Zihang Dai, Eduard Hovy, Thang Luong, and Quoc Le. Unsupervised data augmen-tation for consistency training.NeurIPS, 33, 2020.</p>
</li>
<li><p>Kihyuk Sohn, David Berthelot, Nicholas Carlini, Zizhao Zhang, Han Zhang, Colin A Raf-fel, Ekin Dogus Cubuk, Alexey Kurakin, and Chun-Liang Li. Fixmatch: Simplifying semi-supervised learning with consistency and confidence.NeurIPS, 33, 2020.</p>
</li>
</ul>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://example.com/2021/05/19/YOLO/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="wyukai">
      <meta itemprop="description" content="do">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="yukai">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2021/05/19/YOLO/" class="post-title-link" itemprop="url">YOLO</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>
              

              <time title="创建时间：2021-05-19 19:24:18 / 修改时间：20:03:39" itemprop="dateCreated datePublished" datetime="2021-05-19T19:24:18+08:00">2021-05-19</time>
            </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/deep-learning/" itemprop="url" rel="index"><span itemprop="name">deep learning</span></a>
                </span>
                  ，
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/deep-learning/object-detection/" itemprop="url" rel="index"><span itemprop="name">object detection</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          
      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  


  



          </div>
          

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <p class="site-author-name" itemprop="name">wyukai</p>
  <div class="site-description" itemprop="description">do</div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">5</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/categories/">
          
        <span class="site-state-item-count">3</span>
        <span class="site-state-item-name">分类</span></a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/tags/">
          
        <span class="site-state-item-count">3</span>
        <span class="site-state-item-name">标签</span></a>
      </div>
  </nav>
</div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2021</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">wyukai</span>
</div>
  <div class="powered-by">由 <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> & <a href="https://theme-next.org/" class="theme-link" rel="noopener" target="_blank">NexT.Gemini</a> 强力驱动
  </div>

        








      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/pisces.js"></script>


<script src="/js/next-boot.js"></script>




  















  

  
      

<script>
  if (typeof MathJax === 'undefined') {
    window.MathJax = {
      loader: {
        source: {
          '[tex]/amsCd': '[tex]/amscd',
          '[tex]/AMScd': '[tex]/amscd'
        }
      },
      tex: {
        inlineMath: {'[+]': [['$', '$']]},
        tags: 'ams'
      },
      options: {
        renderActions: {
          findScript: [10, doc => {
            document.querySelectorAll('script[type^="math/tex"]').forEach(node => {
              const display = !!node.type.match(/; *mode=display/);
              const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display);
              const text = document.createTextNode('');
              node.parentNode.replaceChild(text, node);
              math.start = {node: text, delim: '', n: 0};
              math.end = {node: text, delim: '', n: 0};
              doc.math.push(math);
            });
          }, '', false],
          insertedScript: [200, () => {
            document.querySelectorAll('mjx-container').forEach(node => {
              let target = node.parentNode;
              if (target.nodeName.toLowerCase() === 'li') {
                target.parentNode.classList.add('has-jax');
              }
            });
          }, '', false]
        }
      }
    };
    (function () {
      var script = document.createElement('script');
      script.src = '//cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js';
      script.defer = true;
      document.head.appendChild(script);
    })();
  } else {
    MathJax.startup.document.state(0);
    MathJax.texReset();
    MathJax.typeset();
  }
</script>

    

  

</body>
</html>
